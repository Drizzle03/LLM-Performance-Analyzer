"""
Anthropic Claude API í´ë˜ìŠ¤
"""
import time
import asyncio
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

try:
    import anthropic
except ImportError:
    anthropic = None

from ..utils.config import settings


@dataclass
class APIResponse:
    """API ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤"""
    content: str
    tokens_used: int
    response_time: float
    cost: float
    error: Optional[str] = None


class ClaudeAPI:
    """Claude API í´ë˜ìŠ¤"""
    
    def __init__(self):
        """Claude API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not anthropic:
            raise ImportError("anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install anthropic")
        
        if not settings.anthropic_api_key:
            raise ValueError("ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = anthropic.Anthropic(api_key=settings.anthropic_api_key)
        self.model = "claude-3-5-sonnet-20241022"
        
        # ê°€ê²© ì •ë³´ (1M í† í°ë‹¹ ë‹¬ëŸ¬)
        self.input_price_per_million = 3.0  # $3/1M input tokens
        self.output_price_per_million = 15.0  # $15/1M output tokens
    
    async def generate_questions(self, user_response: str, context: str = "") -> APIResponse:
        """
        ì‚¬ìš©ì ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤
        
        Args:
            user_response: ì‚¬ìš©ìì˜ ì‘ë‹µ
            context: ì´ì „ ëŒ€í™” ë§¥ë½
            
        Returns:
            APIResponse: ìƒì„±ëœ ì§ˆë¬¸ë“¤ê³¼ ë©”íƒ€ë°ì´í„°
        """
        prompt = self._build_question_prompt(user_response, context)
        return await self._make_request(prompt)
    
    async def generate_report(self, conversation_history: List[Dict], prompt: str) -> APIResponse:
        """
        ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        
        Args:
            conversation_history: ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
            prompt: ë³´ê³ ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸
            
        Returns:
            APIResponse: ìƒì„±ëœ ë³´ê³ ì„œì™€ ë©”íƒ€ë°ì´í„°
        """
        report_prompt = self._build_report_prompt(conversation_history, prompt)
        return await self._make_request(report_prompt)
    
    def _build_question_prompt(self, user_response: str, context: str) -> str:
        """ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        language = "í•œêµ­ì–´" if settings.test_language == "ko" else "English"
        
        # START ê¸°ë²• íŠ¹í™” í”„ë¡¬í”„íŠ¸
        if "START" in context or "start" in context.lower():
            prompt = f"""
ë‹¹ì‹ ì€ ì·¨ì—… ì¤€ë¹„ìƒì„ ìœ„í•œ ì „ë¬¸ ë©´ì ‘ ì½”ì¹­ AIì…ë‹ˆë‹¤. START ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì·¨ì—…ì¤€ë¹„ìƒì˜ ëª¨í˜¸í•œ ê²½í—˜ì„ **êµ¬ì²´ì ì´ê³  ë§¤ë ¥ì ì¸ ìŠ¤í† ë¦¬**ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

**ì·¨ì—…ì¤€ë¹„ìƒ ê²½í—˜ ë‚´ìš©:**
{user_response}

**ëª©í‘œ**: ìœ„ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ **í•©ê²©í•  ë§Œí•œ ìê¸°ì†Œê°œì„œ**ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ START ê¸°ë²•ì˜ ê° í•­ëª©ë³„ë¡œ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

---

**ğŸ’¡ START ê¸°ë²• ì™„ì„± ê°€ì´ë“œ:**

ê° í•­ëª©ë³„ë¡œ ë‹¤ìŒ 3ê°€ì§€ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
1. **ğŸ” ê¼¬ë¦¬ì§ˆë¬¸**: êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì´ëŒì–´ë‚´ëŠ” ì§ˆë¬¸
2. **ğŸ“‹ ì‹¤ë¬´ ì˜ˆì‹œ**: ì´ í”„ë¡œì íŠ¸ì—ì„œ ìˆì„ë²•í•œ êµ¬ì²´ì ì¸ ìƒí™©/ìˆ˜ì¹˜
3. **â­ ê¸°ì—… ì–´í•„ í¬ì¸íŠ¸**: ìê¸°ì†Œê°œì„œì—ì„œ ê°•ì¡°í•˜ë©´ ì¢‹ì„ í‘œí˜„/í‚¤ì›Œë“œ

---

**ğŸ“ ì‘ë‹µ í˜•ì‹:**

## S (Situation) - ìƒí™©
ğŸ” **ê¼¬ë¦¬ì§ˆë¬¸**: [êµ¬ì²´ì ì¸ ìƒí™©ì„ íŒŒì•…í•˜ëŠ” ì§ˆë¬¸]
ğŸ“‹ **ì‹¤ë¬´ ì˜ˆì‹œ**: [ë§ˆì¼€íŒ… ì¸í„´ì´ ì‹¤ì œë¡œ ê²½í—˜í•  ìˆ˜ ìˆëŠ” ìƒí™© ì˜ˆì‹œ]  
â­ **ê¸°ì—… ì–´í•„**: [ì´ ìƒí™©ì—ì„œ ê°•ì¡°í•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œë‚˜ í‘œí˜„]

## T (Task) - ê³¼ì œ  
ğŸ” **ê¼¬ë¦¬ì§ˆë¬¸**: [ëª…í™•í•œ ëª©í‘œ/ë¬¸ì œë¥¼ ë„ì¶œí•˜ëŠ” ì§ˆë¬¸]
ğŸ“‹ **ì‹¤ë¬´ ì˜ˆì‹œ**: [ì‹¤ì œ ë§ˆì¼€íŒ… ê³¼ì œ ì˜ˆì‹œ]
â­ **ê¸°ì—… ì–´í•„**: [ë¬¸ì œ ì¸ì‹ ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ëŠ” í‘œí˜„]

## A (Action) - í–‰ë™
ğŸ” **ê¼¬ë¦¬ì§ˆë¬¸**: [êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³¼ì •ì„ ë¬»ëŠ” ì§ˆë¬¸]  
ğŸ“‹ **ì‹¤ë¬´ ì˜ˆì‹œ**: [ì‹¤ì œ A/B í…ŒìŠ¤íŠ¸ë‚˜ ë¶„ì„ ë°©ë²• ì˜ˆì‹œ]
â­ **ê¸°ì—… ì–´í•„**: [ì‹¤í–‰ë ¥ê³¼ ë¶„ì„ë ¥ì„ ë³´ì—¬ì£¼ëŠ” í‚¤ì›Œë“œ]

## R (Result) - ê²°ê³¼
ğŸ” **ê¼¬ë¦¬ì§ˆë¬¸**: [ì •ëŸ‰ì  ì„±ê³¼ë¥¼ í™•ì¸í•˜ëŠ” ì§ˆë¬¸]
ğŸ“‹ **ì‹¤ë¬´ ì˜ˆì‹œ**: [ì‹¤ì œ CTR, ì „í™˜ìœ¨ ê°œì„  ìˆ˜ì¹˜ ì˜ˆì‹œ]  
â­ **ê¸°ì—… ì–´í•„**: [ì„±ê³¼ë¥¼ ì„íŒ©íŠ¸ ìˆê²Œ í‘œí˜„í•˜ëŠ” ë°©ë²•]

## T (Takeaway) - êµí›ˆ
ğŸ” **ê¼¬ë¦¬ì§ˆë¬¸**: [ì„±ì¥ê³¼ í•™ìŠµì„ í™•ì¸í•˜ëŠ” ì§ˆë¬¸]
ğŸ“‹ **ì‹¤ë¬´ ì˜ˆì‹œ**: [ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë‚˜ ìŠ¤í‚¬ í–¥ìƒ ì˜ˆì‹œ]
â­ **ê¸°ì—… ì–´í•„**: [ì§€ì†ì  í•™ìŠµê³¼ ì„±ì¥ ì˜ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” í‘œí˜„]

**ì¤‘ìš”**: ê° í•­ëª©ì€ ì·¨ì—…ì¤€ë¹„ìƒì´ **"ì•„, ì´ëŸ° ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë˜ê² êµ¬ë‚˜!"** í•˜ê³  ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        else:
            # ê¸°ë³¸ ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ì—ì„œ ì˜ë¯¸ ìˆëŠ” í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.

ì´ì „ ë§¥ë½: {context}
ì‚¬ìš©ì ì‘ë‹µ: {user_response}

ìœ„ ì‚¬ìš©ì ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ 5ê°œì˜ í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
ì§ˆë¬¸ì€ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:
1. ì‚¬ìš©ìì˜ ì‘ë‹µê³¼ ê´€ë ¨ì„±ì´ ë†’ì„ ê²ƒ
2. ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒ
3. ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”ì‹ì¼ ê²ƒ
4. {language}ë¡œ ì‘ì„±ë  ê²ƒ

ì‘ë‹µ í˜•ì‹:
1. [ì²« ë²ˆì§¸ ì§ˆë¬¸]
2. [ë‘ ë²ˆì§¸ ì§ˆë¬¸]
3. [ì„¸ ë²ˆì§¸ ì§ˆë¬¸]
4. [ë„¤ ë²ˆì§¸ ì§ˆë¬¸]
5. [ë‹¤ì„¯ ë²ˆì§¸ ì§ˆë¬¸]
"""
        
        return prompt
    
    def _build_report_prompt(self, conversation_history: List[Dict], prompt: str) -> str:
        """ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        language = "í•œêµ­ì–´" if settings.test_language == "ko" else "English"
        
        # ëŒ€í™” ê¸°ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        conversation_text = "\n".join([
            f"{'ì‚¬ìš©ì' if msg.get('role') == 'user' else 'AI'}: {msg.get('content', '')}"
            for msg in conversation_history
        ])
        
        report_prompt = f"""
ë‹¤ìŒ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ëŒ€í™” ê¸°ë¡:
{conversation_text}

ë³´ê³ ì„œ ìš”êµ¬ì‚¬í•­: {prompt}

ë³´ê³ ì„œëŠ” ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ìš”ì•½ (Summary)
2. ì£¼ìš” ë‚´ìš© (Main Content)
3. ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ (Analysis & Insights)
4. ê²°ë¡  (Conclusion)

ë³´ê³ ì„œëŠ” {language}ë¡œ ì‘ì„±í•˜ê³ , 500-1000ë‹¨ì–´ ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        return report_prompt
    
    async def _make_request(self, prompt: str) -> APIResponse:
        """ì‹¤ì œ API ìš”ì²­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤"""
        start_time = time.time()
        
        try:
            response = await asyncio.to_thread(
                self.client.messages.create,
                model=self.model,
                max_tokens=2000,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            end_time = time.time()
            response_time = end_time - start_time
            
            # í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚°
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            total_tokens = input_tokens + output_tokens
            
            # ë¹„ìš© ê³„ì‚°
            input_cost = (input_tokens / 1_000_000) * self.input_price_per_million
            output_cost = (output_tokens / 1_000_000) * self.output_price_per_million
            total_cost = input_cost + output_cost
            
            return APIResponse(
                content=response.content[0].text,
                tokens_used=total_tokens,
                response_time=response_time,
                cost=total_cost
            )
            
        except Exception as e:
            end_time = time.time()
            return APIResponse(
                content="",
                tokens_used=0,
                response_time=end_time - start_time,
                cost=0.0,
                error=str(e)
            )
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        return {
            "provider": "Anthropic",
            "model": self.model,
            "input_price_per_million": self.input_price_per_million,
            "output_price_per_million": self.output_price_per_million
        } 