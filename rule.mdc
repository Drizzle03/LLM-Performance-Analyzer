# TIO Prompt Test - AI API 성능 비교 프로젝트 규칙

## 🎯 프로젝트 개요
Claude API와 HyperClovaX API를 포함한 5개 AI 모델의 성능을 비교하는 프로젝트입니다.
- **목적**: 질문 생성 및 보고서 작성 성능을 품질, 속도, 비용 측면에서 비교
- **대상 모델**: Claude, ChatGPT, Gemini, Grok, HyperClovaX
- **특화 기능**: START 기법을 활용한 취업준비생 맞춤형 보고서 생성

## 📁 프로젝트 구조
```
TIO_Prompt_Test/
├── src/
│   ├── api/          # AI API 클래스들
│   ├── cli/          # CLI 도구 (main.py)
│   ├── metrics/      # 평가 시스템 (evaluator.py)
│   ├── tests/        # 테스트 시나리오 (test_scenarios.py)
│   └── utils/        # 설정 관리 (config.py)
├── results/          # 테스트 결과 저장
├── requirements.txt  # 패키지 의존성
└── main.py          # 진입점
```

## 🔧 핵심 개발 규칙

### 1. **함수 호출 검증 필수** 🚨
- 새로운 함수를 코드에 추가할 때는 **반드시 해당 함수가 실제로 구현되었는지 확인**
- 작업 완료 보고 전에 **모든 호출된 함수의 구현 여부를 교차 검증**
- `AttributeError` 방지를 위한 필수 절차

### 2. **API 통합 패턴**
- 모든 AI API는 `APIResponse` 데이터 클래스를 공통으로 사용
- `generate_questions()` vs `generate_report()` 메서드 구분 중요
- 비동기 처리 패턴: `await asyncio.to_thread()` 사용

### 3. **토큰 계산 방식 차이 인식**
- **정확한 토큰 수**: Claude, ChatGPT, Grok (API 제공)
- **추정 토큰 수**: Gemini, HyperClovaX (`len(text.split()) * 1.3`)
- 비용 비교 시 토큰 계산 방식 차이로 인한 왜곡 가능성 고려

### 4. **예외 처리 표준**
```python
failed_apis = set()  # 실패한 API 추적
try:
    # API 호출
    if api_name in failed_apis:
        continue  # 이미 실패한 API는 스킵
except Exception as e:
    error_msg = comparator._get_simplified_error(str(e))
    print(f"❌ {api_name}: {error_msg}")
    failed_apis.add(api_name)
```

## 📊 성능 평가 기준

### 품질 메트릭 (QualityMetrics)
- **관련성 점수**: 키워드 겹침 분석 (1 + overlap_ratio × 4)
- **명확성 점수**: 질문 개수, 물음표 사용률 기반
- **구조 점수**: 번호 매기기, 체계적 구성 평가
- **가독성 점수**: Flesch-Kincaid Grade Level
- **종합 점수**: (관련성 + 명확성 + 구조) / 3

### 성능 메트릭 (PerformanceMetrics)
- 응답 시간, 토큰 사용량, 비용, 성공률
- **랭킹 점수**: 품질×0.6 + 속도×0.2 + 비용효율성×0.2

## 🎭 AI 모델별 특성

### Claude (claude-3-5-sonnet-20241022)
- **가격**: $3.0/$15.0 per 1M tokens
- **특징**: 균형잡힌 성능, 빠른 응답속도
- **강점**: 전통적 보고서 형식에 최적화

### ChatGPT (gpt-4o)
- **가격**: $5.0/$15.0 per 1M tokens  
- **특징**: 실용적 접근, 구체적 수치 제시
- **강점**: 취업준비생이 바로 사용 가능한 내용

### Gemini (gemini-1.5-pro)
- **가격**: $3.5/$10.5 per 1M tokens
- **주의**: 무료 티어 할당량 제한 자주 발생
- **토큰**: 추정 방식으로 부정확할 수 있음

### Grok (grok-3)
- **가격**: $3.0/$15.0 per 1M tokens
- **특징**: 가장 상세하고 전문적인 분석
- **강점**: 면접 준비용 심화 자료에 최적

### HyperClovaX
- **가격**: $2.0/$10.0 per 1M tokens (추정, 실제로는 더 저렴)
- **특징**: 압도적 가성비, 한국어 특화
- **강점**: 빠른 초안 작성, 대량 처리

## 🚀 사용법

### 기본 명령어
```bash
# 질문 생성 테스트
python main.py test --category start_technique --count 1

# 보고서 생성 테스트 (중요!)
python main.py report --category start_technique_report --count 1

# 카테고리 확인
python main.py categories
```

### START 기법 특화 프롬프트 구조
```
각 항목별로 다음 3가지를 제공:
1. 🔍 꼬리질문: 구체적인 정보를 이끌어내는 질문
2. 📋 실무 예시: 프로젝트에서 있을법한 구체적인 상황/수치  
3. ⭐ 기업 어필 포인트: 자기소개서에서 강조하면 좋을 표현/키워드
```

## ⚠️ 주의사항

### 1. **테스트 타입 구분 필수**
- 질문 생성: `generate_questions(user_response, context)`
- 보고서 생성: `generate_report(conversation_history, prompt)`
- **잘못 호출하면 전혀 다른 결과 생성**

### 2. **API 키 관리**
- 환경변수로 관리: `.env` 파일 사용
- HyperClovaX는 Request ID 자동 생성 기능 포함
- API 키 상태 검증: `settings.validate_api_keys()`

### 3. **비용 모니터링**
- HyperClovaX 추정 비용과 실제 비용 차이 가능성
- 대량 테스트 시 비용 제한 설정 권장
- 무료 티어 한도 주의 (특히 Gemini)

## 📈 최적화 팁

### 성능 최적화
- 병렬 API 호출로 속도 향상
- 실패한 API 스킵으로 전체 테스트 중단 방지
- 타임아웃 설정으로 무한 대기 방지

### 비용 최적화  
- 테스트용: `gpt-4o-mini`, `gemini-1.5-flash` 사용
- 프로덕션: 품질과 비용의 균형점 찾기
- HyperClovaX 활용으로 한국어 처리 비용 절감

## 🎯 TIO 서비스 연관성
- **TIO 랜딩페이지**: 자기소개서 작성 전 경험 정리 서비스
- **START 기법**: 취업준비생의 모호한 경험을 구체적 스토리로 변환
- **목표**: "합격할 만한 자기소개서" 작성 지원

이 규칙들을 따라 개발하면 안정적이고 효율적인 AI API 성능 비교가 가능합니다.

## 📋 프롬프트 관리 시스템 규칙 (신규 추가)

### 프롬프트 파일 관리 규칙
- **위치**: 모든 프롬프트는 `src/prompts/` 폴더에 `.txt` 파일로 저장
- **명명 규칙**: `{기능}_{옵션}.txt` (예: `question_generation_start.txt`)
- **인코딩**: UTF-8 필수

### 프롬프트 파일 구조
```
src/prompts/
├── question_generation.txt         # 일반 질문 생성
├── question_generation_simple.txt  # 간단한 질문 생성 (Haiku용)
├── question_generation_start.txt   # START 기법 질문 생성
├── question_generation_start_simple.txt # 간단한 START 질문
└── report_generation.txt           # 보고서 생성
```

### 변수 치환 규칙
- `{user_response}`: 사용자 응답 내용
- `{context}`: 이전 대화 맥락  
- `{conversation_text}`: 전체 대화 기록
- `{prompt}`: 보고서 생성 요구사항
- `{language}`: 언어 설정 (자동 추가)

### 프롬프트 로더 사용법
```python
# ✅ 올바른 사용법
from src.utils.prompt_loader import prompt_loader

prompt = prompt_loader.get_question_prompt(
    user_response=user_input,
    context=context,
    use_start=True,  # START 기법 사용 여부
    simple=False     # 간단한 프롬프트 사용 여부 (Haiku용)
)

# ❌ 직접 하드코딩 금지
prompt = f"질문을 생성해주세요: {user_input}"
```

### 프롬프트 수정 가이드
1. **프롬프트 파일 직접 수정**
2. **캐시 클리어**: `prompt_loader.clear_cache()`
3. **테스트 실행으로 검증**

### 장점
- **중앙 관리**: 모든 프롬프트를 한 곳에서 관리
- **버전 관리**: Git을 통한 프롬프트 변경사항 추적
- **모델별 최적화**: 각 AI 모델 특성에 맞는 프롬프트 제공  
- **유지보수성**: 코드와 프롬프트 분리로 수정 편의성 증대
- **재사용성**: 공통 프롬프트 템플릿 활용
description:
globs:
alwaysApply: false
---
